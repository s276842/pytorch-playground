{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(4.)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number = torch.tensor(4.)\n",
    "number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.float32"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([4])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.tensor([1., 2, 3, 4])\n",
    "print(t2)\n",
    "t2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient\n",
    "\n",
    "We can combine tensors with the usual arithmetic operations. Using *requires_grad* in the initializaiton of a pytorch variabl, we signal to trace its gradient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors.\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "x, w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y = w*x + b, \\qquad x = 3, w = 4, b = 5 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(17., grad_fn=<AddBackward0>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arithmetic operations\n",
    "y = w * x + b\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute derivates, we can invoke the *.backward* method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute derivatives\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: None\n",
      "dy/dw: tensor(3.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Display gradients\n",
    "print('dy/dx:', x.grad)\n",
    "print('dy/dw:', w.grad)\n",
    "print('dy/db:', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[42, 42],\n        [42, 42],\n        [42, 42]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "t2 = torch.full((3, 2), 42)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1,  2],\n        [ 3,  4],\n        [ 5,  6],\n        [42, 42],\n        [42, 42],\n        [42, 42]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = torch.cat((t1, t2))\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.8415,  0.9093],\n        [ 0.1411, -0.7568],\n        [-0.9589, -0.2794],\n        [-0.9165, -0.9165],\n        [-0.9165, -0.9165],\n        [-0.9165, -0.9165]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sin(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(12).reshape(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0848, 0.9763, 0.5962, 0.3564],\n        [0.0794, 0.3084, 0.4527, 0.3402],\n        [0.0330, 0.1467, 0.0355, 0.9896]], dtype=torch.float64)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4 = torch.from_numpy(x)\n",
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/6Ujttb4.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting random weights:\n",
      " tensor([[ 0.8702,  0.0286,  0.1502],\n",
      "        [ 2.4021, -0.9260,  1.0540]], requires_grad=True)\n",
      "\n",
      "Starting random bias:\n",
      " tensor([-0.0211,  0.1151], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "print(f\"Starting random weights:\\n {w}\\n\")\n",
    "print(f\"Starting random bias:\\n {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is simply a function that performs a matrix multiplication of the inputs and the weights w (transposed) and adds the bias b (replicated for each observation).\n",
    "\n",
    "<img src=\"https://i.imgur.com/WGXLFvA.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, w, b):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 71.8808, 158.7490],\n",
      "        [ 91.3002, 204.6750],\n",
      "        [ 88.2346, 146.1478],\n",
      "        [ 95.5283, 244.3089],\n",
      "        [ 73.2861, 150.7452]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs, w, b)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results represent the number of Apples (col 1) and Oranges (col 2) for each region (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -15.8808,  -88.7490],\n",
      "        [ -10.3002, -103.6750],\n",
      "        [  30.7654,  -13.1478],\n",
      "        [ -73.5283, -207.3089],\n",
      "        [  29.7139,  -31.7452]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compare with targets\n",
    "print(targets-preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate how good/bad the model is doing we introduce a *loss* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss - average of squared residuals\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7037.6626, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In average each prediction differs from the actual value for a number of units equal to the square root of this *loss*. Our goal is to minimize the loss function uswith gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8702,  0.0286,  0.1502],\n",
      "        [ 2.4021, -0.9260,  1.0540]], requires_grad=True)\n",
      "tensor([[ 973.9307, -368.5895,   39.6537],\n",
      "        [8078.5786, 5758.6426, 4221.3149]])\n"
     ]
    }
   ],
   "source": [
    "# Gradients for weights\n",
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decrease the loss we must make a small step in the direction opposite of the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * lr\n",
    "    b -= b.grad * lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use torch.no_grad to indicate to PyTorch that we shouldn't track, calculate, or modify gradients while updating the weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5965.0928, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's verify that the loss is actually lower\n",
    "loss = mse(model(inputs, w, b), targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, we reset the gradients to zero by invoking the .zero_() method. We need to do this because PyTorch accumulates gradients. Otherwise, the next time we invoke .backward on the loss, the new gradient values are added to the existing gradients, which may lead to unexpected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 100 epochs\n",
    "def train_model(w, b, k):\n",
    "    loss_list = []\n",
    "    lr = 1e-5\n",
    "    for i in range(100):\n",
    "        preds = model(inputs, w, b)\n",
    "        loss = mse(preds, targets)\n",
    "        loss_list.append(loss)\n",
    "        print(f\"epoch[{i}]: loss1 = {loss:.2f}\")\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            w -= w.grad * lr\n",
    "            b -= b.grad * lr\n",
    "            if( i%k == 0):\n",
    "                w.grad.zero_()\n",
    "                b.grad.zero_()\n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0]: loss1 = 5965.09\n",
      "epoch[1]: loss1 = 5226.91\n",
      "epoch[2]: loss1 = 4714.26\n",
      "epoch[3]: loss1 = 4008.21\n",
      "epoch[4]: loss1 = 3529.61\n",
      "epoch[5]: loss1 = 3514.49\n",
      "epoch[6]: loss1 = 3854.84\n",
      "epoch[7]: loss1 = 4175.54\n",
      "epoch[8]: loss1 = 4094.64\n",
      "epoch[9]: loss1 = 3488.83\n",
      "epoch[10]: loss1 = 2582.35\n",
      "epoch[11]: loss1 = 1798.36\n",
      "epoch[12]: loss1 = 1750.42\n",
      "epoch[13]: loss1 = 1673.12\n",
      "epoch[14]: loss1 = 1591.29\n",
      "epoch[15]: loss1 = 1519.72\n",
      "epoch[16]: loss1 = 1454.05\n",
      "epoch[17]: loss1 = 1375.15\n",
      "epoch[18]: loss1 = 1263.79\n",
      "epoch[19]: loss1 = 1115.67\n",
      "epoch[20]: loss1 = 946.40\n",
      "epoch[21]: loss1 = 782.97\n",
      "epoch[22]: loss1 = 771.75\n",
      "epoch[23]: loss1 = 750.58\n",
      "epoch[24]: loss1 = 721.29\n",
      "epoch[25]: loss1 = 685.35\n",
      "epoch[26]: loss1 = 643.32\n",
      "epoch[27]: loss1 = 595.06\n",
      "epoch[28]: loss1 = 540.61\n",
      "epoch[29]: loss1 = 480.92\n",
      "epoch[30]: loss1 = 418.18\n",
      "epoch[31]: loss1 = 355.27\n",
      "epoch[32]: loss1 = 350.80\n",
      "epoch[33]: loss1 = 342.02\n",
      "epoch[34]: loss1 = 329.24\n",
      "epoch[35]: loss1 = 312.82\n",
      "epoch[36]: loss1 = 293.14\n",
      "epoch[37]: loss1 = 270.65\n",
      "epoch[38]: loss1 = 245.83\n",
      "epoch[39]: loss1 = 219.29\n",
      "epoch[40]: loss1 = 191.74\n",
      "epoch[41]: loss1 = 163.95\n",
      "epoch[42]: loss1 = 161.96\n",
      "epoch[43]: loss1 = 158.04\n",
      "epoch[44]: loss1 = 152.29\n",
      "epoch[45]: loss1 = 144.85\n",
      "epoch[46]: loss1 = 135.92\n",
      "epoch[47]: loss1 = 125.70\n",
      "epoch[48]: loss1 = 114.47\n",
      "epoch[49]: loss1 = 102.49\n",
      "epoch[50]: loss1 = 90.06\n",
      "epoch[51]: loss1 = 77.51\n",
      "epoch[52]: loss1 = 76.61\n",
      "epoch[53]: loss1 = 74.84\n",
      "epoch[54]: loss1 = 72.23\n",
      "epoch[55]: loss1 = 68.86\n",
      "epoch[56]: loss1 = 64.80\n",
      "epoch[57]: loss1 = 60.16\n",
      "epoch[58]: loss1 = 55.06\n",
      "epoch[59]: loss1 = 49.61\n",
      "epoch[60]: loss1 = 43.97\n",
      "epoch[61]: loss1 = 38.26\n",
      "epoch[62]: loss1 = 37.85\n",
      "epoch[63]: loss1 = 37.04\n",
      "epoch[64]: loss1 = 35.84\n",
      "epoch[65]: loss1 = 34.30\n",
      "epoch[66]: loss1 = 32.45\n",
      "epoch[67]: loss1 = 30.32\n",
      "epoch[68]: loss1 = 27.99\n",
      "epoch[69]: loss1 = 25.49\n",
      "epoch[70]: loss1 = 22.90\n",
      "epoch[71]: loss1 = 20.27\n",
      "epoch[72]: loss1 = 20.08\n",
      "epoch[73]: loss1 = 19.71\n",
      "epoch[74]: loss1 = 19.16\n",
      "epoch[75]: loss1 = 18.44\n",
      "epoch[76]: loss1 = 17.58\n",
      "epoch[77]: loss1 = 16.60\n",
      "epoch[78]: loss1 = 15.51\n",
      "epoch[79]: loss1 = 14.34\n",
      "epoch[80]: loss1 = 13.13\n",
      "epoch[81]: loss1 = 11.90\n",
      "epoch[82]: loss1 = 11.81\n",
      "epoch[83]: loss1 = 11.63\n",
      "epoch[84]: loss1 = 11.37\n",
      "epoch[85]: loss1 = 11.03\n",
      "epoch[86]: loss1 = 10.62\n",
      "epoch[87]: loss1 = 10.15\n",
      "epoch[88]: loss1 = 9.63\n",
      "epoch[89]: loss1 = 9.07\n",
      "epoch[90]: loss1 = 8.48\n",
      "epoch[91]: loss1 = 7.89\n",
      "epoch[92]: loss1 = 7.84\n",
      "epoch[93]: loss1 = 7.75\n",
      "epoch[94]: loss1 = 7.62\n",
      "epoch[95]: loss1 = 7.45\n",
      "epoch[96]: loss1 = 7.25\n",
      "epoch[97]: loss1 = 7.01\n",
      "epoch[98]: loss1 = 6.75\n",
      "epoch[99]: loss1 = 6.46\n"
     ]
    }
   ],
   "source": [
    "losses1 = train_model(w, b,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0]: loss1 = 13817.23\n",
      "epoch[1]: loss1 = 9517.01\n",
      "epoch[2]: loss1 = 6616.68\n",
      "epoch[3]: loss1 = 4659.74\n",
      "epoch[4]: loss1 = 3338.58\n",
      "epoch[5]: loss1 = 2445.88\n",
      "epoch[6]: loss1 = 1841.95\n",
      "epoch[7]: loss1 = 1432.65\n",
      "epoch[8]: loss1 = 1154.53\n",
      "epoch[9]: loss1 = 964.85\n",
      "epoch[10]: loss1 = 834.78\n",
      "epoch[11]: loss1 = 744.93\n",
      "epoch[12]: loss1 = 682.19\n",
      "epoch[13]: loss1 = 637.76\n",
      "epoch[14]: loss1 = 605.69\n",
      "epoch[15]: loss1 = 581.98\n",
      "epoch[16]: loss1 = 563.93\n",
      "epoch[17]: loss1 = 549.72\n",
      "epoch[18]: loss1 = 538.11\n",
      "epoch[19]: loss1 = 528.30\n",
      "epoch[20]: loss1 = 519.71\n",
      "epoch[21]: loss1 = 511.98\n",
      "epoch[22]: loss1 = 504.84\n",
      "epoch[23]: loss1 = 498.14\n",
      "epoch[24]: loss1 = 491.74\n",
      "epoch[25]: loss1 = 485.58\n",
      "epoch[26]: loss1 = 479.60\n",
      "epoch[27]: loss1 = 473.76\n",
      "epoch[28]: loss1 = 468.04\n",
      "epoch[29]: loss1 = 462.43\n",
      "epoch[30]: loss1 = 456.91\n",
      "epoch[31]: loss1 = 451.47\n",
      "epoch[32]: loss1 = 446.11\n",
      "epoch[33]: loss1 = 440.82\n",
      "epoch[34]: loss1 = 435.60\n",
      "epoch[35]: loss1 = 430.46\n",
      "epoch[36]: loss1 = 425.37\n",
      "epoch[37]: loss1 = 420.36\n",
      "epoch[38]: loss1 = 415.40\n",
      "epoch[39]: loss1 = 410.51\n",
      "epoch[40]: loss1 = 405.68\n",
      "epoch[41]: loss1 = 400.91\n",
      "epoch[42]: loss1 = 396.20\n",
      "epoch[43]: loss1 = 391.55\n",
      "epoch[44]: loss1 = 386.96\n",
      "epoch[45]: loss1 = 382.43\n",
      "epoch[46]: loss1 = 377.95\n",
      "epoch[47]: loss1 = 373.53\n",
      "epoch[48]: loss1 = 369.16\n",
      "epoch[49]: loss1 = 364.85\n",
      "epoch[50]: loss1 = 360.59\n",
      "epoch[51]: loss1 = 356.38\n",
      "epoch[52]: loss1 = 352.23\n",
      "epoch[53]: loss1 = 348.13\n",
      "epoch[54]: loss1 = 344.08\n",
      "epoch[55]: loss1 = 340.08\n",
      "epoch[56]: loss1 = 336.13\n",
      "epoch[57]: loss1 = 332.23\n",
      "epoch[58]: loss1 = 328.38\n",
      "epoch[59]: loss1 = 324.57\n",
      "epoch[60]: loss1 = 320.82\n",
      "epoch[61]: loss1 = 317.11\n",
      "epoch[62]: loss1 = 313.44\n",
      "epoch[63]: loss1 = 309.83\n",
      "epoch[64]: loss1 = 306.25\n",
      "epoch[65]: loss1 = 302.73\n",
      "epoch[66]: loss1 = 299.24\n",
      "epoch[67]: loss1 = 295.80\n",
      "epoch[68]: loss1 = 292.40\n",
      "epoch[69]: loss1 = 289.05\n",
      "epoch[70]: loss1 = 285.73\n",
      "epoch[71]: loss1 = 282.46\n",
      "epoch[72]: loss1 = 279.23\n",
      "epoch[73]: loss1 = 276.04\n",
      "epoch[74]: loss1 = 272.88\n",
      "epoch[75]: loss1 = 269.77\n",
      "epoch[76]: loss1 = 266.70\n",
      "epoch[77]: loss1 = 263.66\n",
      "epoch[78]: loss1 = 260.66\n",
      "epoch[79]: loss1 = 257.70\n",
      "epoch[80]: loss1 = 254.78\n",
      "epoch[81]: loss1 = 251.89\n",
      "epoch[82]: loss1 = 249.04\n",
      "epoch[83]: loss1 = 246.22\n",
      "epoch[84]: loss1 = 243.44\n",
      "epoch[85]: loss1 = 240.69\n",
      "epoch[86]: loss1 = 237.98\n",
      "epoch[87]: loss1 = 235.30\n",
      "epoch[88]: loss1 = 232.65\n",
      "epoch[89]: loss1 = 230.04\n",
      "epoch[90]: loss1 = 227.46\n",
      "epoch[91]: loss1 = 224.91\n",
      "epoch[92]: loss1 = 222.39\n",
      "epoch[93]: loss1 = 219.91\n",
      "epoch[94]: loss1 = 217.45\n",
      "epoch[95]: loss1 = 215.03\n",
      "epoch[96]: loss1 = 212.63\n",
      "epoch[97]: loss1 = 210.27\n",
      "epoch[98]: loss1 = 207.93\n",
      "epoch[99]: loss1 = 205.62\n"
     ]
    }
   ],
   "source": [
    "w2 = torch.randn(2, 3, requires_grad=True)\n",
    "b2 = torch.randn(2, requires_grad=True)\n",
    "losses2 = train_model(w2, b2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-31-0824c913f4f5>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlosses1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"1\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlosses2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"2\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlegend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kaloo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\pyplot.py\u001B[0m in \u001B[0;36mplot\u001B[1;34m(scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2838\u001B[0m \u001B[1;33m@\u001B[0m\u001B[0m_copy_docstring_and_deprecators\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mAxes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2839\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscalex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscaley\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2840\u001B[1;33m     return gca().plot(\n\u001B[0m\u001B[0;32m   2841\u001B[0m         \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscalex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mscalex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscaley\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mscaley\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2842\u001B[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001B[1;32mc:\\users\\kaloo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001B[0m in \u001B[0;36mplot\u001B[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1741\u001B[0m         \"\"\"\n\u001B[0;32m   1742\u001B[0m         \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcbook\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormalize_kwargs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmlines\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLine2D\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1743\u001B[1;33m         \u001B[0mlines\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_lines\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1744\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mline\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mlines\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1745\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_line\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kaloo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m    271\u001B[0m                 \u001B[0mthis\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    272\u001B[0m                 \u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 273\u001B[1;33m             \u001B[1;32myield\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_plot_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    274\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    275\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_next_color\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kaloo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001B[0m in \u001B[0;36m_plot_args\u001B[1;34m(self, tup, kwargs)\u001B[0m\n\u001B[0;32m    387\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtup\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    388\u001B[0m             \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_check_1d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtup\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 389\u001B[1;33m             \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_check_1d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtup\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    390\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    391\u001B[0m             \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mindex_of\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtup\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kaloo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001B[0m in \u001B[0;36m_check_1d\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   1293\u001B[0m     \u001B[1;34m\"\"\"Convert scalars to 1d arrays; pass-through arrays as is.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1294\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'shape'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1295\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0matleast_1d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1296\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1297\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36matleast_1d\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kaloo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\core\\shape_base.py\u001B[0m in \u001B[0;36matleast_1d\u001B[1;34m(*arys)\u001B[0m\n\u001B[0;32m     64\u001B[0m     \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mary\u001B[0m \u001B[1;32min\u001B[0m \u001B[0marys\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 66\u001B[1;33m         \u001B[0mary\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0masanyarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mary\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     67\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mary\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mary\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kaloo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\core\\_asarray.py\u001B[0m in \u001B[0;36masanyarray\u001B[1;34m(a, dtype, order, like)\u001B[0m\n\u001B[0;32m    169\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0m_asanyarray_with_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlike\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlike\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    170\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 171\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msubok\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    172\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    173\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kaloo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\tensor.py\u001B[0m in \u001B[0;36m__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m    619\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__array__\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    620\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 621\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    622\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    623\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(100), losses1, label=\"1\")\n",
    "plt.plot(range(100), losses2, label=\"2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression using PyTorch built-ins\n",
    "We've implemented linear regression & gradient descent model using some basic tensor operations. However, since this is a common pattern in deep learning, PyTorch provides several built-in functions and classes to make it easy to create and train models with just a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 73.,  67.,  43.],\n        [ 91.,  88.,  64.],\n        [ 87., 134.,  58.],\n        [102.,  43.,  37.],\n        [ 69.,  96.,  70.],\n        [ 74.,  66.,  43.],\n        [ 91.,  87.,  65.],\n        [ 88., 134.,  59.],\n        [101.,  44.,  37.],\n        [ 68.,  96.,  71.],\n        [ 73.,  66.,  44.],\n        [ 92.,  87.,  64.],\n        [ 87., 135.,  57.],\n        [103.,  43.,  36.],\n        [ 68.,  97.,  70.]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70], \n",
    "                   [74, 66, 43], \n",
    "                   [91, 87, 65], \n",
    "                   [88, 134, 59], \n",
    "                   [101, 44, 37], \n",
    "                   [68, 96, 71], \n",
    "                   [73, 66, 44], \n",
    "                   [92, 87, 64], \n",
    "                   [87, 135, 57], \n",
    "                   [103, 43, 36], \n",
    "                   [68, 97, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119],\n",
    "                    [57, 69], \n",
    "                    [80, 102], \n",
    "                    [118, 132], \n",
    "                    [21, 38], \n",
    "                    [104, 118], \n",
    "                    [57, 69], \n",
    "                    [82, 100], \n",
    "                    [118, 134], \n",
    "                    [20, 38], \n",
    "                    [102, 120]], \n",
    "                   dtype='float32')\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 73.,  67.,  43.],\n         [ 91.,  88.,  64.],\n         [ 87., 134.,  58.]]),\n tensor([[ 56.,  70.],\n         [ 81., 101.],\n         [119., 133.]]))"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorDataset allows us to access a small section of the training data using the array indexing notation ([0:3] in the above code). It returns a tuple with two elements. The first element contains the input variables for the selected rows, and the second contains the targets.\n",
    "\n",
    "We'll also create a DataLoader, which can split the data into batches of a predefined size while training. It also provides other utilities like shuffling and random sampling of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 92.,  87.,  64.],\n",
      "        [ 73.,  67.,  43.],\n",
      "        [101.,  44.,  37.],\n",
      "        [ 87., 135.,  57.],\n",
      "        [ 68.,  96.,  71.]])\n",
      "tensor([[ 82., 100.],\n",
      "        [ 56.,  70.],\n",
      "        [ 21.,  38.],\n",
      "        [118., 134.],\n",
      "        [104., 118.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model loading\n",
    "Instead of initializing the weights & biases manually, we can define the model using the nn.Linear class from PyTorch, which does it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3554, -0.4510,  0.2152],\n",
      "        [-0.2543, -0.0348, -0.1468]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2510, 0.4019], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define model\n",
    "model = nn.Linear(3, 2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch models also have a helpful .parameters method, which returns a list containing all the weights and bias matrices present in the model. For our linear regression model, we have one weight matrix and one bias matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[Parameter containing:\n tensor([[ 0.3554, -0.4510,  0.2152],\n         [-0.2543, -0.0348, -0.1468]], requires_grad=True),\n Parameter containing:\n tensor([0.2510, 0.4019], requires_grad=True)]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[  5.2305, -26.8086],\n        [  6.6751, -35.2007],\n        [-16.7829, -34.9047],\n        [ 25.0698, -32.4661],\n        [ -3.4606, -30.7659],\n        [  6.0368, -27.0281],\n        [  7.3413, -35.3127],\n        [-16.2123, -35.3059],\n        [ 24.2634, -32.2466],\n        [ -3.6008, -30.6585],\n        [  5.8966, -26.9206],\n        [  7.4815, -35.4201],\n        [-17.4490, -34.7927],\n        [ 25.2100, -32.5736],\n        [ -4.2670, -30.5465]], grad_fn=<AddmmBackward>)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12111.2471, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Import nn.functional\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = F.mse_loss\n",
    "\n",
    "loss = loss_fn(model(inputs), targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that model.parameters() is passed as an argument to optim.SGD so that the optimizer knows which matrices should be modified during the update step. In complex models different branches of the structure can use different optimizers, so not all the parameters of the network must be passed.\n",
    "Also, we can specify a learning rate that controls the amount by which the parameters are modified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 939.6053\n",
      "Epoch [20/100], Loss: 644.2755\n",
      "Epoch [30/100], Loss: 69.4752\n",
      "Epoch [40/100], Loss: 215.5510\n",
      "Epoch [50/100], Loss: 58.9203\n",
      "Epoch [60/100], Loss: 153.0536\n",
      "Epoch [70/100], Loss: 96.8771\n",
      "Epoch [80/100], Loss: 11.6436\n",
      "Epoch [90/100], Loss: 33.1873\n",
      "Epoch [100/100], Loss: 30.0437\n"
     ]
    }
   ],
   "source": [
    "fit(100, model, loss_fn, opt, train_dl)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}